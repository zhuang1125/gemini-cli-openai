/**
 * Constants for the Gemini CLI OpenAI Worker
 */

// Static reasoning messages for thinking models
export const REASONING_MESSAGES = [
	"ğŸ” **Analyzing the request: \"{requestPreview}\"**\n\n",
	"ğŸ¤” Let me think about this step by step... ",
	"ğŸ’­ I need to consider the context and provide a comprehensive response. ",
	"ğŸ¯ Based on my understanding, I should address the key points while being accurate and helpful. ",
	"âœ¨ Let me formulate a clear and structured answer.\n\n"
];

// Default reasoning delay between chunks (in milliseconds)
export const REASONING_CHUNK_DELAY = 100;
